{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning at Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. \n",
    "\n",
    "Imagine that you want to compete on Jeopardy, and you're looking for any way to win. In this project, I'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which you can download here. Here's the beginning of the file:\n",
    "\n",
    "Here are explanations of each column:\n",
    "\n",
    "- Show Number - the Jeopardy episode number\n",
    "- Air Date - the date the episode aired\n",
    "- Round - the round of Jeopardy\n",
    "- Category - the category of the question\n",
    "- Value - the number of dollars the correct answer is worth\n",
    "- Question - the text of the question\n",
    "- Answer - the text of the answer\n",
    "\n",
    "And below is a sample and some information about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# Read dataset into dataframe\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "#Show first 5 rows. \n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before analysis can begin I need to normalize all of the data. For example, I need to make sure that all strings are in lower case and that numeric values are integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShowNumber</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "      <td>of 8 12 or 18 the number of us states that tou...</td>\n",
       "      <td>18</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "      <td>the new power generation</td>\n",
       "      <td>prince</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "      <td>in 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>galileo</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "      <td>before the grand jury she said im really sorry...</td>\n",
       "      <td>monica lewinsky</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "      <td>llamas are the heftiest south american members...</td>\n",
       "      <td>camels</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ShowNumber    AirDate      Round                         Category  \\\n",
       "0            4680 2004-12-31  Jeopardy!                          HISTORY   \n",
       "1            4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2            4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3            4680 2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4            4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "...           ...        ...        ...                              ...   \n",
       "19994        3582 2000-03-14  Jeopardy!                   U.S. GEOGRAPHY   \n",
       "19995        3582 2000-03-14  Jeopardy!               POP MUSIC PAIRINGS   \n",
       "19996        3582 2000-03-14  Jeopardy!                  HISTORIC PEOPLE   \n",
       "19997        3582 2000-03-14  Jeopardy!                  1998 QUOTATIONS   \n",
       "19998        3582 2000-03-14  Jeopardy!                       LLAMA-RAMA   \n",
       "\n",
       "      Value                                           Question  \\\n",
       "0      $200  For the last 8 years of his life, Galileo was ...   \n",
       "1      $200  No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2      $200  The city of Yuma in this state has a record av...   \n",
       "3      $200  In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4      $200  Signer of the Dec. of Indep., framer of the Co...   \n",
       "...     ...                                                ...   \n",
       "19994  $200  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995  $200                      ...& the New Power Generation   \n",
       "19996  $200  In 1589 he was appointed professor of mathemat...   \n",
       "19997  $200  Before the grand jury she said, \"I'm really so...   \n",
       "19998  $200  Llamas are the heftiest South American members...   \n",
       "\n",
       "                Answer                                     clean_question  \\\n",
       "0           Copernicus  for the last 8 years of his life galileo was u...   \n",
       "1           Jim Thorpe  no 2 1912 olympian football star at carlisle i...   \n",
       "2              Arizona  the city of yuma in this state has a record av...   \n",
       "3           McDonald's  in 1963 live on the art linkletter show this c...   \n",
       "4           John Adams  signer of the dec of indep framer of the const...   \n",
       "...                ...                                                ...   \n",
       "19994               18  of 8 12 or 18 the number of us states that tou...   \n",
       "19995           Prince                           the new power generation   \n",
       "19996          Galileo  in 1589 he was appointed professor of mathemat...   \n",
       "19997  Monica Lewinsky  before the grand jury she said im really sorry...   \n",
       "19998           Camels  llamas are the heftiest south american members...   \n",
       "\n",
       "          clean_answer  clean_value  \n",
       "0           copernicus          200  \n",
       "1           jim thorpe          200  \n",
       "2              arizona          200  \n",
       "3            mcdonalds          200  \n",
       "4           john adams          200  \n",
       "...                ...          ...  \n",
       "19994               18          200  \n",
       "19995           prince          200  \n",
       "19996          galileo          200  \n",
       "19997  monica lewinsky          200  \n",
       "19998           camels          200  \n",
       "\n",
       "[19999 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "# Remove spaces from column titles\n",
    "jeopardy.columns = jeopardy.columns.str.replace(\" \",'')\n",
    "\n",
    "# Function to remove punctuation and upper case\n",
    "def normalize(value):\n",
    "    value = value.lower()\n",
    "    value = re.sub('[^A-Za-z0-9\\s]', '', value)\n",
    "    value = re.sub(\"\\s+\", \" \", value)\n",
    "    return value\n",
    "\n",
    "# Create clean answer and question columns\n",
    "jeopardy[\"clean_question\"] = jeopardy['Question'].apply(normalize)\n",
    "jeopardy[\"clean_answer\"] = jeopardy['Answer'].apply(normalize)\n",
    "\n",
    "\n",
    "# Clean value columns\n",
    "def normalize_2(value):\n",
    "    value = re.sub('[^A-Za-z0-9\\s]', ' ', value)\n",
    "    try:\n",
    "        value = int(value)\n",
    "    except Exception:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "# Create clean value column\n",
    "jeopardy[\"clean_value\"] = jeopardy['Value'].apply(normalize_2)\n",
    "\n",
    "# Change Air date column to datetime object\n",
    "jeopardy['AirDate'] = pd.to_datetime(jeopardy[\"AirDate\"])\n",
    "# Show\n",
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above the data has now been normalized and I can begin to analyze.\n",
    "\n",
    "The first thing I will check is to see how often the answer is included in the question. Perhaps it is a good stratergy to find the answer in the words of the question asked.\n",
    "\n",
    "# Is the answer in the question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the answer is in the question: 0.059001965249777744\n"
     ]
    }
   ],
   "source": [
    "# Create function to find answers in questions\n",
    "def answers_in_questions(row):\n",
    "    # Split questions by word\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    # Remove 'the'\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    # Loop through and add 1 for each repeated word\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "# Apply function to dataset\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(answers_in_questions, axis=1)\n",
    "# Find mean\n",
    "average = jeopardy[\"answer_in_question\"].mean()\n",
    "# Print\n",
    "print(\"Probability that the answer is in the question: {}\".format(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average the answer is in the question less than 6% of the time. Not enough to help really. In Jeopardy you lose the value of the question if you get the answer wrong. Gambling on a 6% chance is not a winning stratergy. \n",
    "\n",
    "The next thing I will check to see is if questions are repeated often. If they are then we could study the common ones and increase our chance of winning.\n",
    "\n",
    "# Are Questions Reused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "audio clue                                                                                                          5\n",
       "his pride had cast him out from heaven with all his host of rebel angels                                            2\n",
       "these fell great oaks                                                                                               2\n",
       "when it absolutely positively has to be there overnight                                                             2\n",
       "adam levine                                                                                                         2\n",
       "common in dixie a razorback is a wild one of these                                                                  2\n",
       "1967 we rob banks                                                                                                   2\n",
       "poi a luau treat is made from these mashed roots                                                                    2\n",
       "in nicolais opera the merry wives of windsor this fat funny rogue gets dumped into the river in a laundry basket    2\n",
       "Name: clean_question, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find questions that come up more than once. \n",
    "repeated_questions = jeopardy['clean_question'].value_counts()\n",
    "repeated_questions = repeated_questions[repeated_questions >= 2]\n",
    "repeated_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 20,000 questions only 9 have been repeated. One of these is titled 'audio clue' and some of these are quite criptic and require added context by knowing the topic of the round. This therefore does not help us. However, although the question may not repeated word for word perhaps there are complex words (6+ characters) that pop up in many questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that complex words are in past questions: 0.6908737315671878\n"
     ]
    }
   ],
   "source": [
    "# Probability that complex words are in older questions.\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "jeopardy.sort_values(\"AirDate\")\n",
    "\n",
    "# Loop through and find words from previous questions\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q)> 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count / len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "# Apply function\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "average_2 = jeopardy[\"question_overlap\"].mean()\n",
    "print(\"Probability that complex words are in past questions: {}\".format(average_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 70% is encouraging but it should be pointed out that these are just words and not phrases. It can therefore be difficult to assertain the context of how the word is used. However, the 70% is encouraging enough to look in more detail. Let's dig a little deeper. \n",
    "\n",
    "Another column that we have is the value column. Each question is worth a different amount. I am now going to see if the high value questions (800 +) are more likely to have words that have been used in past questions:\n",
    "\n",
    "\n",
    "# High Value or Low Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to define high or low value\n",
    "def find_value(value, axis=1):\n",
    "    if value > 800:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply function\n",
    "jeopardy[\"high_value\"] = jeopardy['clean_value'].apply(find_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2],\n",
       " [1, 4],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words in high and low value questions\n",
    "def usage(value):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        clean_question = row[7].split()\n",
    "        if value in clean_question:\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return [high_count, low_count]\n",
    "\n",
    "from random import sample\n",
    "\n",
    "# Find expected proportion of words in past questions\n",
    "comparison_terms = sample(terms_used, 10)\n",
    "observed_expected = []\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(usage(word))\n",
    "    \n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.661742197378053, pvalue=0.4159455550913673),\n",
       " Power_divergenceResult(statistic=0.06325251982741063, pvalue=0.8014271475031749),\n",
       " Power_divergenceResult(statistic=0.3308710986890265, pvalue=0.565146603267378),\n",
       " Power_divergenceResult(statistic=3.022325020112631, pvalue=0.08212564786568953),\n",
       " Power_divergenceResult(statistic=0.3308710986890265, pvalue=0.565146603267378),\n",
       " Power_divergenceResult(statistic=0.661742197378053, pvalue=0.4159455550913673),\n",
       " Power_divergenceResult(statistic=0.661742197378053, pvalue=0.4159455550913673),\n",
       " Power_divergenceResult(statistic=0.3308710986890265, pvalue=0.565146603267378),\n",
       " Power_divergenceResult(statistic=0.3308710986890265, pvalue=0.565146603267378),\n",
       " Power_divergenceResult(statistic=0.3308710986890265, pvalue=0.565146603267378)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Filter high and low values\n",
    "high_value_count = len(jeopardy[jeopardy[\"high_value\"] == 1])\n",
    "low_value_count = len(jeopardy[jeopardy[\"high_value\"] == 0])\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "# Find chi value and p value\n",
    "for high, low in observed_expected:\n",
    "    total = high + low\n",
    "    total_prop = total / len(jeopardy)\n",
    "    high_expected = total_prop * high_value_count\n",
    "    low_expected = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([high, low])\n",
    "    expected = np.array([high_expected, low_expected])\n",
    "    \n",
    "    chi_values = chisquare(observed, expected)\n",
    "    chi_squared.append(chi_values)\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the P values are below 5% so there is nothing statistically significant here. High value questions are no more likely to repeat than low value question. \n",
    "\n",
    "The next step is to take a closer look at the most common complex words. I am going to find the complex words that appear in over 1% of questions.\n",
    "\n",
    "# Popular Qustion Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'president': 1.29,\n",
       " 'island': 1.08,\n",
       " 'country': 2.38,\n",
       " 'targetblankherea': 1.22,\n",
       " 'called': 2.605,\n",
       " 'french': 1.215,\n",
       " 'famous': 1.23,\n",
       " 'capital': 1.285,\n",
       " 'became': 1.435,\n",
       " 'played': 1.485,\n",
       " 'before': 1.335,\n",
       " 'american': 1.285}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = {}\n",
    "\n",
    "# Find common words in questions\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q)> 5]\n",
    "    for word in split_question:\n",
    "        if word in value_counts:\n",
    "            value_counts[word] += 1\n",
    "        else:\n",
    "            value_counts[word] = 1\n",
    "        \n",
    "# Only words above 1%\n",
    "above_200 = {}\n",
    "for key, value in value_counts.items():\n",
    "    if value >= 200:\n",
    "        above_200[key] = round((value / 20000) * 100, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "above_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few topics that a jeopady conestant could study are presidents, countries and capitals.**\n",
    "\n",
    "Let's use the same technique to check out the categories column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HISTORY': 0.2,\n",
       " 'IN THE DICTIONARY': 0.155,\n",
       " 'TRAVEL & TOURISM': 0.15,\n",
       " 'SCIENCE': 0.175,\n",
       " 'WORD ORIGINS': 0.19,\n",
       " 'TELEVISION': 0.255,\n",
       " 'ANNUAL EVENTS': 0.16,\n",
       " 'MEDICINE': 0.15,\n",
       " 'WORLD GEOGRAPHY': 0.165,\n",
       " 'AMERICAN HISTORY': 0.2,\n",
       " 'POTPOURRI': 0.15,\n",
       " 'SCIENCE & NATURE': 0.175,\n",
       " 'AUTHORS': 0.195,\n",
       " 'MAGAZINES': 0.175,\n",
       " 'U.S. GEOGRAPHY': 0.25,\n",
       " 'RHYME TIME': 0.175,\n",
       " 'BIRDS': 0.155,\n",
       " 'FICTIONAL CHARACTERS': 0.155,\n",
       " 'SPORTS': 0.18,\n",
       " 'LITERATURE': 0.225,\n",
       " 'WORLD CAPITALS': 0.185,\n",
       " 'ISLANDS': 0.15,\n",
       " 'HISTORIC NAMES': 0.16,\n",
       " 'BEFORE & AFTER': 0.2,\n",
       " 'OPERA': 0.15,\n",
       " 'BODIES OF WATER': 0.18,\n",
       " 'WORLD HISTORY': 0.16,\n",
       " 'U.S. PRESIDENTS': 0.15}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common categories\n",
    "value_counts = {}\n",
    "\n",
    "for word in jeopardy[\"Category\"] :\n",
    "    if word in value_counts:\n",
    "        value_counts[word] += 1\n",
    "    else:\n",
    "        value_counts[word] = 1\n",
    "        \n",
    "# Filter common categories\n",
    "above_30 = {}\n",
    "for key, value in value_counts.items():\n",
    "    if value >= 30:\n",
    "        above_30[key] = round((value / 20000) * 100, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "above_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we have capitals and presidents.\n",
    "\n",
    "Notice that some of these have repeating words. For example, we have history and American history. Let's see which words pop up in the categories most common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HISTORY': 0.19,\n",
       " 'WORDS': 0.32,\n",
       " 'SPORTS': 0.165,\n",
       " 'WORLD': 0.3,\n",
       " 'MOVIES': 0.165,\n",
       " 'STATE': 0.155,\n",
       " 'MUSIC': 0.155,\n",
       " 'MOVIE': 0.16,\n",
       " 'CENTURY': 0.295}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common words in categories\n",
    "word_count = {}\n",
    "for words in value_counts.keys():\n",
    "    split_categories = words.split()\n",
    "    split_categories = [w for w in split_categories if len(w) > 4]\n",
    "    for word in split_categories:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "            \n",
    "\n",
    "# Filter common words in categories\n",
    "above_30 = {}\n",
    "for key, value in word_count.items():\n",
    "    if value >= 30:\n",
    "        above_30[key] = round((value / 20000) * 100, 3)\n",
    "\n",
    "above_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best categories to study are listed above. \n",
    "\n",
    "Jeopardy also has different rounds. The most important round by far is final jeopardy where contestants have the chance to double their money. Let's see if there are any categories that come up a lot in the final jeopardy round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORD ORIGINS           8\n",
       "U.S. PRESIDENTS        5\n",
       "AUTHORS                4\n",
       "FAMOUS NAMES           4\n",
       "AMERICAN LITERATURE    3\n",
       "POETS                  3\n",
       "SPACE EXPLORATION      3\n",
       "WORLD CITIES           3\n",
       "ASIA                   3\n",
       "WORLD GEOGRAPHY        3\n",
       "U.S. STATES            3\n",
       "ARTISTS                3\n",
       "WORLD LEADERS          3\n",
       "SCIENTISTS             3\n",
       "THE 50 STATES          3\n",
       "FAMOUS WOMEN           3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter final round questions\n",
    "final_jeopardy = jeopardy[jeopardy[\"Round\"] == \"Final Jeopardy!\"]\n",
    "# Categories that appear more than once\n",
    "counts = final_jeopardy['Category'].value_counts()\n",
    "counts = counts[counts > 2]\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word orgins is up there again as are other common categories and questions we have seen before like presidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "\n",
    "- The answer is only included in the question 6% of the time. Using words from the question to find the answer is an unhelpful technique.\n",
    "- Questions are almost never repeated word for word. \n",
    "- Words pop up in old questions 70% of the time. There does seem to be some overlap in at least the type of questions being asked even if they are not word for word. \n",
    "- The value of the question does not affect how likely is is to have been repeated before.\n",
    "**My best advice to a Jeopady contestant.**\n",
    "- Judging by common words in past questions and the categories column I would suggest studying U.S presidents, world capitals, countries and word origins. History and geography are popular topics but are a little broad. Making sure that you know the names of all the presidents and capitals is doable and could come in very helpful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
